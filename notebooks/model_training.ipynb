{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40c511c6-20a3-4dba-bc7c-b316d43c87b3",
   "metadata": {},
   "source": [
    "# **Model Training: Gas Turbina**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462af47-6fc9-4894-8c8d-e04b5a469638",
   "metadata": {},
   "source": [
    "Since the EDA showed some non-linearity in Turbine Energy Yield (TEY) with respect to features, we will use models that capture these non-linearities.\n",
    "\n",
    "Models:\n",
    "\n",
    "- Randon Forests\n",
    "- XGboost\n",
    "- Neural Networks\n",
    "- Ensemble Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe05b8e9-779e-480b-ad01-c120247272e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "import torch\n",
    "\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "# data's 2011\n",
    "gt_2011 = pd.read_csv('../data/gas_turbine_emision/gt_2011.csv' )\n",
    "gt_2011['Year'] = 2011\n",
    "\n",
    "# data's 2012\n",
    "gt_2012 = pd.read_csv('../data/gas_turbine_emision/gt_2012.csv' )\n",
    "gt_2012['Year'] = 2014\n",
    "\n",
    "# data's 2013\n",
    "gt_2013 = pd.read_csv('../data/gas_turbine_emision/gt_2013.csv' )\n",
    "gt_2013['Year'] = 2013\n",
    "\n",
    "# data's 2014\n",
    "gt_2014 = pd.read_csv('../data/gas_turbine_emision/gt_2014.csv' )\n",
    "gt_2014['Year'] = 2014\n",
    "\n",
    "# data's 2015\n",
    "gt_2015 = pd.read_csv('../data/gas_turbine_emision/gt_2015.csv' )\n",
    "gt_2015['Year'] = 2015\n",
    "\n",
    "\n",
    "gt = pd.concat([gt_2011, gt_2012, gt_2013, gt_2014, gt_2015], ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da122470-8873-4234-9cf9-bee071e59964",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# simple feature engineer\n",
    "\n",
    "gt['TAT_TIT_Ratio'] = gt['TAT'] / gt['TIT']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a4c1e8-7c9d-46c1-ab6d-bb000fb9e412",
   "metadata": {
    "tags": []
   },
   "source": [
    "### **Random Forests**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8599c832-bd82-48f2-9742-5d5bf283791f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6270042034451444\n",
      "R2 Score: 0.9983868712020609\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split data\n",
    "X = gt.drop(columns=['TEY'])\n",
    "y = gt['TEY']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "# Train model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e576fb9f-28d9-41b6-9abf-153de26a799e",
   "metadata": {},
   "source": [
    "### **XGboost**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e3906c1-1393-43e7-8e56-e66f41d7fde5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.6741293039685858\n",
      "R2 Score: 0.9981352760372852\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Train model\n",
    "model = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fb6c7b-23be-4aa2-884b-2c0e4051b5d4",
   "metadata": {},
   "source": [
    "### **SVR**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "004ba3af-f2c0-4d8d-afc8-a4b0cc47c380",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 12.900700270031024\n",
      "R2 Score: 0.3171037782499224\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "# Train model\n",
    "model = SVR(kernel='rbf')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e37664-4647-4922-a42c-6b635910c58d",
   "metadata": {},
   "source": [
    "### **Neural Network**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75cd149-8611-42a5-9701-fb11972cb485",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 15.8230\n",
      "Epoch [2/50], Loss: 12.0738\n",
      "Epoch [3/50], Loss: 11.9437\n",
      "Epoch [4/50], Loss: 13.7326\n",
      "Epoch [5/50], Loss: 9.9565\n",
      "Epoch [6/50], Loss: 4.8949\n",
      "Epoch [7/50], Loss: 5.2905\n",
      "Epoch [8/50], Loss: 2.3011\n",
      "Epoch [9/50], Loss: 1.6876\n",
      "Epoch [10/50], Loss: 1.3890\n",
      "Epoch [11/50], Loss: 1.8725\n",
      "Epoch [12/50], Loss: 1.3269\n",
      "Epoch [13/50], Loss: 1.4471\n",
      "Epoch [14/50], Loss: 1.9581\n",
      "Epoch [15/50], Loss: 2.6491\n",
      "Epoch [16/50], Loss: 1.1991\n",
      "Epoch [17/50], Loss: 2.4160\n",
      "Epoch [18/50], Loss: 2.5304\n",
      "Epoch [19/50], Loss: 2.6530\n",
      "Epoch [20/50], Loss: 1.7775\n",
      "Epoch [21/50], Loss: 1.7783\n",
      "Epoch [22/50], Loss: 1.8708\n",
      "Epoch [23/50], Loss: 1.4341\n",
      "Epoch [24/50], Loss: 1.2975\n",
      "Epoch [25/50], Loss: 0.9303\n",
      "Epoch [26/50], Loss: 1.6207\n",
      "Epoch [27/50], Loss: 1.7251\n",
      "Epoch [28/50], Loss: 1.0305\n",
      "Epoch [29/50], Loss: 2.0330\n",
      "Epoch [30/50], Loss: 1.5242\n",
      "Epoch [31/50], Loss: 0.9900\n",
      "Epoch [32/50], Loss: 1.5950\n",
      "Epoch [33/50], Loss: 1.5506\n",
      "Epoch [34/50], Loss: 1.2276\n",
      "Epoch [35/50], Loss: 1.9028\n",
      "Epoch [36/50], Loss: 2.1568\n",
      "Epoch [37/50], Loss: 1.4372\n",
      "Epoch [38/50], Loss: 1.9510\n",
      "Epoch [39/50], Loss: 1.2005\n",
      "Epoch [40/50], Loss: 1.9503\n",
      "Epoch [41/50], Loss: 1.0801\n",
      "Epoch [42/50], Loss: 1.2644\n",
      "Epoch [43/50], Loss: 1.3969\n",
      "Epoch [44/50], Loss: 1.0947\n",
      "Epoch [45/50], Loss: 1.2800\n",
      "Epoch [46/50], Loss: 1.8267\n",
      "Epoch [47/50], Loss: 1.7367\n",
      "Epoch [48/50], Loss: 1.3545\n",
      "Epoch [49/50], Loss: 0.9383\n",
      "Epoch [50/50], Loss: 1.4171\n",
      "RMSE: 1.5834263917077562\n",
      "R2 Score: 0.9897121671813256\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming train and test are Pandas DataFrames\n",
    "# Example: train and test have columns 'feature1', 'feature2', ..., 'target'\n",
    "\n",
    "# Separate features (X) and target (y) for train and test\n",
    "X_train_np = X_train.values  # Convert DataFrame to numpy array\n",
    "y_train_np = y_train.values\n",
    "X_test_np = X_test.values\n",
    "y_test_np = y_test.values\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32)\n",
    "\n",
    "# Create a DataLoader for training\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Define the Neural Network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)  # Input layer to hidden layer (64 neurons)\n",
    "        self.fc2 = nn.Linear(64, 32)         # Hidden layer (64 neurons) to hidden layer (32 neurons)\n",
    "        self.fc3 = nn.Linear(32, 1)          # Hidden layer (32 neurons) to output layer (1 neuron)\n",
    "        self.relu = nn.ReLU()                # Activation function\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)  # No activation for regression output\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "model = SimpleNN(input_dim)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()  # Root Mean Squared Error Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)  # Adam optimizer\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set model to training mode\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        # Forward pass\n",
    "        outputs = model(batch_X)\n",
    "        loss = torch.sqrt( criterion(outputs, batch_y.unsqueeze(1)) )  # Add extra dimension to batch_y\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Print loss for each epoch\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluation\n",
    "model.eval()  # Set model to evaluation mode\n",
    "with torch.no_grad():\n",
    "    y_pred_tensor = model(X_test_tensor)\n",
    "    y_pred = y_pred_tensor.numpy()  # Convert predictions to numpy array\n",
    "\n",
    "# Calculate RMSE and R2 Score\n",
    "rmse = mean_squared_error(y_test, y_pred, squared=False)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('RMSE:', rmse)\n",
    "print('R2 Score:', r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ff99a7-66fd-43d0-9f78-5fc9f45460ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06c95d44-bc55-4bf9-a9ec-220d13e19106",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 16.6000\n",
      "Epoch [2/50], Loss: 17.4160\n",
      "Epoch [3/50], Loss: 17.1187\n",
      "Epoch [4/50], Loss: 11.2346\n",
      "Epoch [5/50], Loss: 5.5927\n",
      "Epoch [6/50], Loss: 8.6207\n",
      "Epoch [7/50], Loss: 4.0801\n",
      "Epoch [8/50], Loss: 3.6201\n",
      "Epoch [9/50], Loss: 3.4901\n",
      "Epoch [10/50], Loss: 2.4927\n",
      "Epoch [11/50], Loss: 3.3552\n",
      "Epoch [12/50], Loss: 2.1293\n",
      "Epoch [13/50], Loss: 3.1068\n",
      "Epoch [14/50], Loss: 1.6472\n",
      "Epoch [15/50], Loss: 1.9279\n",
      "Epoch [16/50], Loss: 1.4969\n",
      "Epoch [17/50], Loss: 1.2768\n",
      "Epoch [18/50], Loss: 1.8642\n",
      "Epoch [19/50], Loss: 2.2314\n",
      "Epoch [20/50], Loss: 2.7275\n",
      "Epoch [21/50], Loss: 1.5079\n",
      "Epoch [22/50], Loss: 1.9655\n",
      "Epoch [23/50], Loss: 1.7608\n",
      "Epoch [24/50], Loss: 1.5440\n",
      "Epoch [25/50], Loss: 1.2751\n",
      "Epoch [26/50], Loss: 2.3007\n",
      "Epoch [27/50], Loss: 2.2722\n",
      "Epoch [28/50], Loss: 2.2310\n",
      "Epoch [29/50], Loss: 1.2280\n",
      "Epoch [30/50], Loss: 1.8400\n",
      "Epoch [31/50], Loss: 0.8457\n",
      "Epoch [32/50], Loss: 1.6057\n",
      "Epoch [33/50], Loss: 2.7278\n",
      "Epoch [34/50], Loss: 1.8290\n",
      "Epoch [35/50], Loss: 2.3259\n",
      "Epoch [36/50], Loss: 2.2565\n",
      "Epoch [37/50], Loss: 1.4377\n",
      "Epoch [38/50], Loss: 1.7553\n",
      "Epoch [39/50], Loss: 1.0124\n",
      "Epoch [40/50], Loss: 1.4639\n",
      "Epoch [41/50], Loss: 1.3777\n",
      "Epoch [42/50], Loss: 2.4988\n",
      "Epoch [43/50], Loss: 1.7057\n",
      "Epoch [44/50], Loss: 1.2587\n",
      "Epoch [45/50], Loss: 0.9966\n",
      "Epoch [46/50], Loss: 1.4841\n",
      "Epoch [47/50], Loss: 1.3098\n",
      "Epoch [48/50], Loss: 1.3766\n",
      "Epoch [49/50], Loss: 0.9177\n",
      "Epoch [50/50], Loss: 1.1939\n",
      "RMSE: 1.5071855\n",
      "R2 Score: 0.9906790214168287\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Separate features (X) and target (y) for train and test\n",
    "X_train_np = X_train.values  # Convert DataFrame to numpy array\n",
    "y_train_np = y_train.values\n",
    "X_test_np = X_test.values\n",
    "y_test_np = y_test.values\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "\n",
    "\n",
    "# Define model\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 64)\n",
    "        self.bn1 = nn.BatchNorm1d(64)  # Normalización Batch\n",
    "        self.dropout1 = nn.Dropout(0.05)  # Dropout de 20%\n",
    "\n",
    "        self.fc2 = nn.Linear(64, 32)\n",
    "        self.bn2 = nn.BatchNorm1d(32)  # Normalización Batch\n",
    "        self.dropout2 = nn.Dropout(0.1)  # Dropout de 20%\n",
    "\n",
    "        self.fc3 = nn.Linear(32, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(  self.fc1(x)  )\n",
    "        # x = self.dropout1(x)\n",
    "        x = torch.relu( self.fc2(x)   ) \n",
    "        # x = self.dropout2(x)\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "# Initialize model\n",
    "model = SimpleModel(X_train.shape[1])\n",
    "\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.sqrt(nn.MSELoss()(y_pred, y_true) + 1e-8)\n",
    "\n",
    "criterion = RMSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Train model\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_X)\n",
    "        loss = criterion(y_pred, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "    \n",
    "# Evaluate\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor).numpy()\n",
    "\n",
    "y_test_np = y_test_tensor.numpy()\n",
    "print('RMSE:', mean_squared_error(y_test_np, y_pred, squared=False))\n",
    "print('R2 Score:', r2_score(y_test_np, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20e89365-015e-4425-b3fa-ab74b9176277",
   "metadata": {},
   "source": [
    "### **Linear Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65bacd9a-b458-4c29-ad00-83f91b737b38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9507531359552979\n",
      "R2 Score: 0.9962909415885439\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Train model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85f22208-6501-4468-a80c-b9f04699ad63",
   "metadata": {},
   "source": [
    "**Implementation Neural Network Sequential**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eda2542a-560b-45ba-b2d4-e956e3326e2d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Loss: 20.3533\n",
      "Epoch [2/50], Loss: 7.3787\n",
      "Epoch [3/50], Loss: 14.7957\n",
      "Epoch [4/50], Loss: 16.0361\n",
      "Epoch [5/50], Loss: 9.5628\n",
      "Epoch [6/50], Loss: 10.6319\n",
      "Epoch [7/50], Loss: 9.1049\n",
      "Epoch [8/50], Loss: 11.3360\n",
      "Epoch [9/50], Loss: 6.3958\n",
      "Epoch [10/50], Loss: 3.5614\n",
      "Epoch [11/50], Loss: 2.6150\n",
      "Epoch [12/50], Loss: 1.9737\n",
      "Epoch [13/50], Loss: 1.3646\n",
      "Epoch [14/50], Loss: 1.9268\n",
      "Epoch [15/50], Loss: 1.1691\n",
      "Epoch [16/50], Loss: 1.2018\n",
      "Epoch [17/50], Loss: 0.9832\n",
      "Epoch [18/50], Loss: 2.0750\n",
      "Epoch [19/50], Loss: 1.1936\n",
      "Epoch [20/50], Loss: 1.3323\n",
      "Epoch [21/50], Loss: 0.9930\n",
      "Epoch [22/50], Loss: 1.0422\n",
      "Epoch [23/50], Loss: 1.3470\n",
      "Epoch [24/50], Loss: 1.6193\n",
      "Epoch [25/50], Loss: 1.4352\n",
      "Epoch [26/50], Loss: 1.1866\n",
      "Epoch [27/50], Loss: 2.0838\n",
      "Epoch [28/50], Loss: 2.9976\n",
      "Epoch [29/50], Loss: 0.6158\n",
      "Epoch [30/50], Loss: 1.7780\n",
      "Epoch [31/50], Loss: 1.2854\n",
      "Epoch [32/50], Loss: 1.3691\n",
      "Epoch [33/50], Loss: 1.4150\n",
      "Epoch [34/50], Loss: 1.5902\n",
      "Epoch [35/50], Loss: 1.3733\n",
      "Epoch [36/50], Loss: 2.1383\n",
      "Epoch [37/50], Loss: 1.0914\n",
      "Epoch [38/50], Loss: 3.0236\n",
      "Epoch [39/50], Loss: 1.5237\n",
      "Epoch [40/50], Loss: 0.9600\n",
      "Epoch [41/50], Loss: 1.4965\n",
      "Epoch [42/50], Loss: 2.0014\n",
      "Epoch [43/50], Loss: 1.9703\n",
      "Epoch [44/50], Loss: 1.6424\n",
      "Epoch [45/50], Loss: 1.1835\n",
      "Epoch [46/50], Loss: 1.4895\n",
      "Epoch [47/50], Loss: 1.0802\n",
      "Epoch [48/50], Loss: 1.6311\n",
      "Epoch [49/50], Loss: 0.9337\n",
      "Epoch [50/50], Loss: 1.6164\n",
      "RMSE: 1.4691209\n",
      "R2 Score: 0.9911438859344479\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Separate features (X) and target (y) for train and test\n",
    "X_train_np = X_train.values  # Convert DataFrame to numpy array\n",
    "y_train_np = y_train.values\n",
    "X_test_np = X_test.values\n",
    "y_test_np = y_test.values\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_np, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_np, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test_np, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test_np, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "\n",
    "# Define model using Sequential\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(X_train.shape[1], 64),\n",
    "   # nn.BatchNorm1d(64),\n",
    "    nn.ReLU(), \n",
    "    nn.Linear(64, 32),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(32, 1)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "\n",
    "\n",
    "class RMSELoss(nn.Module):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        return torch.sqrt(nn.MSELoss()(y_pred, y_true))\n",
    "\n",
    "criterion = RMSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Train model\n",
    "for epoch in range(50):\n",
    "    for batch_X, batch_y in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(batch_X)\n",
    "        loss = criterion(y_pred, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Evaluate\n",
    "with torch.no_grad():\n",
    "    y_pred = model(X_test_tensor).numpy()\n",
    "\n",
    "y_test_np = y_test_tensor.numpy()\n",
    "print('RMSE:', mean_squared_error(y_test_np, y_pred, squared=False))\n",
    "print('R2 Score:', r2_score(y_test_np, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23048a69-dedf-4cc6-bac3-960d7c20fe06",
   "metadata": {},
   "source": [
    "### **Ensemble Method**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "845b7921-078d-4d38-9242-560ba29a0d7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.650799902164649\n",
      "R2 Score: 0.9982621067451478\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define models\n",
    "model1 = LinearRegression()\n",
    "model2 = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model3 = XGBRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
    "\n",
    "# Create ensemble\n",
    "ensemble = VotingRegressor(estimators=[('lr', model1), ('rf', model2), ('xgb', model3)])\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = ensemble.predict(X_test)\n",
    "print('RMSE:', mean_squared_error(y_test, y_pred, squared=False))\n",
    "print('R2 Score:', r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35890e9c-bacc-4a70-a0ab-d20ec74960be",
   "metadata": {},
   "source": [
    "The best implementation are Random Forest and XGboost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
